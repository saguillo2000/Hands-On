{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation of Linear Regression model prediction\n",
    "\n",
    "$ y = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n}x_{n} $\n",
    "\n",
    "- y is the predicted value.\n",
    "- n is the number of features\n",
    "- $x_{i}$ is the $i^{th}$ feature value\n",
    "- $\\theta_{j}$ is the $j^{th}$ model parameter (including the bias term $\\theta_{0}$ and the feature weights $\\theta_{1},\\theta_{2},...,\\theta_{n}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be written much more concisely using a vectorized form:\n",
    "\n",
    "$y = h_{\\theta}(x) = \\theta Â· x$ \n",
    "\n",
    "- $\\theta$ is the model's parameter vector, containing the bias term $\\theta_{0}$ and the feature weights $\\theta_{1}$ to $\\theta_{n}$.\n",
    "- x is the instance's feature vector, containing $x_{0}$ to $x_{n}$, with $x_{0}$ always equal to 1.\n",
    "- $\\theta . x$ is the dot product of the vectors $\\theta$ and $x$, which is of course equal to $\\theta_{0}x_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n}x_{n}$.\n",
    "- $h_{\\theta}$ is the hypothesis function, using the model parameters $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a Linear Reegression model, we need to find the value of $\\theta$ that minimizes the RMSE. In practice, it is simpler to minimize the mean square error (MSE) than the RMSE, and it leads to the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation of MSE cost function for a Linear Regression model:\n",
    "\n",
    "$MSE(X,h_{\\theta}) = \\frac{1}{m} \\sum_{i=1}^{m} (\\theta^{T}x^{(i)} - y^{(i)})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the value of $\\theta$ that minimizes the cost function, there is a mathematical equation that gives the result directly called the Normal Equation:\n",
    "\n",
    "$\\theta = (X^{(T)}X)^{-1} X^{T}  y$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "- $\\theta$ is the value of $\\theta$ that minimizes the cost function.\n",
    "- y is the vector of target values containing $y^{1}$ to $y^{m}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
