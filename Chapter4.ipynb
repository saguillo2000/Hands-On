{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation of Linear Regression model prediction\n",
    "\n",
    "$ \\hat{y} = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n}x_{n} $\n",
    "\n",
    "- y is the predicted value.\n",
    "- n is the number of features\n",
    "- $x_{i}$ is the $i^{th}$ feature value\n",
    "- $\\theta_{j}$ is the $j^{th}$ model parameter (including the bias term $\\theta_{0}$ and the feature weights $\\theta_{1},\\theta_{2},...,\\theta_{n}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be written much more concisely using a vectorized form:\n",
    "\n",
    "$\\hat{y} = h_{\\theta}(x) = \\theta Â· x$ \n",
    "\n",
    "- $\\theta$ is the model's parameter vector, containing the bias term $\\theta_{0}$ and the feature weights $\\theta_{1}$ to $\\theta_{n}$.\n",
    "- x is the instance's feature vector, containing $x_{0}$ to $x_{n}$, with $x_{0}$ always equal to 1.\n",
    "- $\\theta . x$ is the dot product of the vectors $\\theta$ and $x$, which is of course equal to $\\theta_{0}x_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + ... + \\theta_{n}x_{n}$.\n",
    "- $h_{\\theta}$ is the hypothesis function, using the model parameters $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a Linear Reegression model, we need to find the value of $\\theta$ that minimizes the RMSE. In practice, it is simpler to minimize the mean square error (MSE) than the RMSE, and it leads to the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation of MSE cost function for a Linear Regression model:\n",
    "\n",
    "$MSE(X,h_{\\theta}) = \\frac{1}{m} \\sum_{i=1}^{m} (\\theta^{T}x^{(i)} - y^{(i)})^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the value of $\\theta$ that minimizes the cost function, there is a mathematical equation that gives the result directly called the Normal Equation:\n",
    "\n",
    "$\\hat{\\theta} = (X^{(T)}X)^{-1} X^{T}  y$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "- $\\theta$ is the value of $\\theta$ that minimizes the cost function.\n",
    "- y is the vector of target values containing $y^{1}$ to $y^{m}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.78041666],\n",
       "       [2.98439917]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b = np.c_[np.ones((100,1)), X] # add Xtheta = 1 to each instance\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function used to generate the data was $y = 4 + 3x_{1} +$ Gaussian noise. In our random set the values that came from theta_best are better because they adapt better in the data with the noise. Now we can make predictions with theta_best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.78041666],\n",
       "       [9.749215  ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2,1)), X_new]\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.78041666]), array([[2.98439917]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.78041666],\n",
       "       [9.749215  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.78041666],\n",
       "       [2.98439917]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond =1e-6,)\n",
    "theta_best_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function computes $\\hat{\\theta} = X^{+}y$, where $X^{+}$ is the pseudoinverse of X(specifically, the Moore-Penrose inverse). You can use np.linalg.pinv() to compute the pseudoinverse directly. \n",
    "\n",
    "The pseudoinverse itself is computed using a standard matrix factorization technique called *Singular Value Decomposition* (SVD) that descompose the training set matrix into the matrix multiplication of three matrices $U \\sum V^{T}$. The approach is more efficient than computing the Normal Equation, plus it handles edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Descent* is generic optimization algorithm capable of finding optimal solutions to a wide range of problems. The general idea of Gradient Descent is to tweak parameters iteratively in order to minimize a cost function.\n",
    "\n",
    "You start by filling $\\theta$ with random values(this is called *random initialization*). Then you improve it gradually, taking one baby step at a time, each step attempting to decrease the cost function(e.g.m the MSE), until the algorithm *converges* to a minimum.\n",
    "\n",
    "An important parameter in Gradient Descent is the size of the steps, determined by the *learning rate* hyperparameter. If it is too small, there is going to be needed a lot of iterations. On the other hand, if it is too high it is possible to not have a convergence.\n",
    "\n",
    "If the random initialization starts the algorithm on the left, then it will converge to a *local minimum*, which is not as good as the *global minimum*.\n",
    "\n",
    "When using Gradient Descent, you should ensure that all features have a similar scale(Scikit-Learn's StandardScaler class), or else it will take much longer to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement Gradient Descent, you need to compute the gradient of the cost function with regard to each model parameter $\\theta_{j}$. You need to calculate how much the cost functiom is going to change $\\theta_{j}$, this is called *partial derivative*.\n",
    "\n",
    "Equation Partial derivative of the cost function\n",
    "\n",
    "$\\frac{\\partial}{\\partial \\theta_{j}}$ MSE($\\theta$)= $\\frac{2}{m}\\sum_{i=1}^{m} (\\theta^{T}x^{(i)} - y^{(i)})x_{j}^{(i)}$\n",
    "\n",
    "Instead of computing these partial derivative individually, you can use the next equation to compute them all in one go. The gradient vector contains all the partial derivatives of the cost function (one for each model parameter).\n",
    "\n",
    "Equation gradient vector of the cost function\n",
    "\n",
    "$\\nabla_{\\theta}$MSE($\\theta$) = $\\frac{2}{m}X^{T}(X\\theta -y)$\n",
    "\n",
    "The algortihm is called *Batch Gradient Descent*, because this formula involves calculations over the full training set **X**.As a result it is terribly slow on very large training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.78041666],\n",
       "       [2.98439917]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) -y)\n",
    "    theta = theta - eta*gradients\n",
    "    \n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good learning rate, you can use grid search. However, you may want to limit the number of iterations so that grid search can eliminate models that take too long to converge.\n",
    "\n",
    "A simple to soltions to find the number of iterations is to set a very large number of iterations but not interrupt the algorithm when the gradient vector becomes tiny - that is, when its norm becomes smaller than a tiny number $\\epsilon$(called the tolerance) - because this happen when Gradient Descent has (almost) reached the minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of using the Batch Gradient Descent is that it uses the whole training set. At the opposite site, *Stochastic Gradient Descent* picks a random instance in the training set at every step and computes the gradients based only on that single instance. It will be faster for the fact that is less data.\n",
    "\n",
    "On the other hand, due its stochastic nature, this algortihm is much less regular than Batch Gradient Descent: instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, decreasing only on average. Over time it will end up very close to the minimum, but once it gets there it will continue to bounce around, never settling down. So once the algorithm stops, the final parameter values are good, but not optimal.\n",
    "\n",
    "When the cost function is very irregular, Stochastic Gradient Descent has a better chance to find the global minimum than Batch Gradient Descent.\n",
    "\n",
    "The function that determines the learning rate at each iteration is called *learning schedule*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.81677789],\n",
       "       [2.95171209]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50  #learning schedule hyperparameters\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m + 1)\n",
    "        theta = theta - eta * gradients\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using SGD, the training instances must be independent and identically distributed to ensure that the parameters get pulled toward the global optimum, on average. A simple way to ensure this is to shuffle the instances during training, if you don't shuffle the instances then SGD will start by optimizing for one one label, then the next, and so on, and it will not settle close to the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.71753649]), array([2.99446433]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X,y.ravel())\n",
    "\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
